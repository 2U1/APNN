{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import glob \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(119)\n",
    "np.random.seed(119)\n",
    "random.seed(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransfrom():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(phase='train'):\n",
    "    rootpath = './data/'\n",
    "    target_path = os.path.join(rootpath+phase+'/*.png')\n",
    "    print(target_path)\n",
    "    \n",
    "    path_list = []\n",
    "    \n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/*.png\n",
      "./data/val/*.png\n"
     ]
    }
   ],
   "source": [
    "train_list = make_datapath_list(phase='train')\n",
    "val_list = make_datapath_list(phase='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDataset(data.Dataset):\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        self.labels = {}\n",
    "\n",
    "        if phase == 'train':\n",
    "            with open('./data/annotations/train.txt') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    self.labels[line.split()[0]] = line.split()[1]\n",
    "\n",
    "        elif phase == 'val':\n",
    "            with open('./data/annotations/val.txt') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    self.labels[line.split()[0]] = line.split()[1]\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "\n",
    "        if self.phase=='train':\n",
    "            label_index = img_path[13:]\n",
    "            label = int(self.labels[label_index])\n",
    "\n",
    "\n",
    "        elif self.phase=='val':\n",
    "            label_index = img_path[11:]\n",
    "            label = int(self.labels[label_index])\n",
    "\n",
    "        return img_transformed, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrafficDataset(file_list=train_list, transform=ImageTransfrom(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), phase='train')\n",
    "val_dataset = TrafficDataset(file_list=val_list, transform=ImageTransfrom(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), phase='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32])\n",
      "tensor([ 7, 17,  4, 11, 27, 32, 14, 35, 15, 11, 32, 31, 37, 16, 23, 34, 18, 13,\n",
      "        13,  6, 35, 36,  4, 33, 19, 24, 35, 37, 29,  6, 39, 35,  1,  3, 40, 12,\n",
      "         5,  5, 22,  8, 40,  8, 29, 31, 15, 41, 12,  0, 35, 36, 35, 16, 28, 27,\n",
      "        29,  8, 17,  6, 25,  4, 13, 11, 42,  0, 42,  3, 35, 32, 30,  9, 19, 41,\n",
      "        20, 35,  1, 26,  8, 40, 16, 14,  0, 11, 42, 18, 17,  2, 41, 29, 26, 25,\n",
      "        29, 19, 11,  4,  4, 34, 32, 15,  7, 26, 25,  3, 29, 18, 26, 19, 17, 13,\n",
      "        40, 15, 33, 10, 21, 33, 42, 23,  1, 28, 28, 21, 30,  6,  3, 14, 18,  7,\n",
      "        37, 10, 39, 30, 10, 39, 29,  2,  7, 39,  3,  4,  4,  5, 11, 30,  6,  5,\n",
      "         3, 42, 31, 15, 11, 25, 33, 39,  5,  2, 19, 30,  8, 37, 18, 40, 19,  1,\n",
      "        39,  4, 22, 28, 26, 40, 28, 26, 14, 15,  9, 11, 26, 14, 16, 28, 32, 28,\n",
      "        10, 38, 26, 38,  5, 37, 35, 19, 14, 22, 27,  8,  2, 21,  1, 40, 10, 19,\n",
      "        25, 12, 29, 41,  1, 18,  5, 26, 11, 13, 28, 14,  9,  7, 23, 38, 17, 39,\n",
      "        17, 22,  7, 33, 28, 23, 17, 39, 21, 27, 31,  0, 27,  0,  9, 19, 22, 21,\n",
      "         1, 14, 42,  3, 25,  3, 11, 14, 16,  9, 37,  3, 17, 25, 28,  3, 36,  4,\n",
      "        30,  2,  3, 18])\n"
     ]
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders['train'])\n",
    "inputs, labels = next(batch_iterator)\n",
    "print(inputs.size())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shorcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shorcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shorcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(num_classes=43).to(DEVICE)\n",
    "EPOCHS = 300\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        if (epoch+1)  % 10 == 0:\n",
    "            print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "            print('-------------')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            for inputs, labels in dataloaders_dict[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "                epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            if (epoch+1)  % 10 == 0:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300\n",
      "-------------\n",
      "train Loss: 0.0786 Acc: 0.9784\n",
      "val Loss: 0.5067 Acc: 0.8794\n",
      "Epoch 20/300\n",
      "-------------\n",
      "train Loss: 0.0553 Acc: 0.9859\n",
      "val Loss: 0.2241 Acc: 0.9293\n",
      "Epoch 30/300\n",
      "-------------\n",
      "train Loss: 0.0472 Acc: 0.9881\n",
      "val Loss: 0.3014 Acc: 0.9195\n",
      "Epoch 40/300\n",
      "-------------\n",
      "train Loss: 0.0490 Acc: 0.9876\n",
      "val Loss: 0.4696 Acc: 0.8642\n",
      "Epoch 50/300\n",
      "-------------\n",
      "train Loss: 0.0443 Acc: 0.9888\n",
      "val Loss: 0.2671 Acc: 0.9349\n",
      "Epoch 60/300\n",
      "-------------\n",
      "train Loss: 0.0059 Acc: 0.9997\n",
      "val Loss: 0.0923 Acc: 0.9762\n",
      "Epoch 70/300\n",
      "-------------\n",
      "train Loss: 0.0063 Acc: 0.9998\n",
      "val Loss: 0.0966 Acc: 0.9719\n",
      "Epoch 80/300\n",
      "-------------\n",
      "train Loss: 0.0066 Acc: 0.9998\n",
      "val Loss: 0.0955 Acc: 0.9741\n",
      "Epoch 90/300\n",
      "-------------\n",
      "train Loss: 0.0077 Acc: 0.9995\n",
      "val Loss: 0.1173 Acc: 0.9637\n",
      "Epoch 100/300\n",
      "-------------\n",
      "train Loss: 0.0094 Acc: 0.9992\n",
      "val Loss: 0.1214 Acc: 0.9698\n",
      "Epoch 110/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.1042 Acc: 0.9728\n",
      "Epoch 120/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 0.9999\n",
      "val Loss: 0.1023 Acc: 0.9719\n",
      "Epoch 130/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.0956 Acc: 0.9739\n",
      "Epoch 140/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.1002 Acc: 0.9728\n",
      "Epoch 150/300\n",
      "-------------\n",
      "train Loss: 0.0048 Acc: 1.0000\n",
      "val Loss: 0.1009 Acc: 0.9721\n",
      "Epoch 160/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.0997 Acc: 0.9753\n",
      "Epoch 170/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0992 Acc: 0.9717\n",
      "Epoch 180/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0994 Acc: 0.9728\n",
      "Epoch 190/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0983 Acc: 0.9744\n",
      "Epoch 200/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.0990 Acc: 0.9744\n",
      "Epoch 210/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0992 Acc: 0.9726\n",
      "Epoch 220/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.1002 Acc: 0.9737\n",
      "Epoch 230/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0974 Acc: 0.9739\n",
      "Epoch 240/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.1010 Acc: 0.9728\n",
      "Epoch 250/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.1008 Acc: 0.9737\n",
      "Epoch 260/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0961 Acc: 0.9730\n",
      "Epoch 270/300\n",
      "-------------\n",
      "train Loss: 0.0048 Acc: 1.0000\n",
      "val Loss: 0.0951 Acc: 0.9753\n",
      "Epoch 280/300\n",
      "-------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "val Loss: 0.0968 Acc: 0.9746\n",
      "Epoch 290/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0955 Acc: 0.9748\n",
      "Epoch 300/300\n",
      "-------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.0994 Acc: 0.9730\n"
     ]
    }
   ],
   "source": [
    "train_model(net, dataloaders, criterion, optimizer, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './weights/ResNet.pth'\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe294e6606534daba89c1dc14d4f5ef002211ec8430f3955bebe6e14ba2710b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
